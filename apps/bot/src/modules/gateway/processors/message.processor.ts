/**
 * Mixed Content Handler - X·ª≠ l√Ω t·∫•t c·∫£ lo·∫°i tin nh·∫Øn
 */

import { CONFIG } from '../../../core/config/config.js';
import { debugLog, logError, logStep } from '../../../core/logger/logger.js';
import {
  extractYouTubeUrls,
  generateContent,
  generateContentStream,
  type MediaPart,
} from '../../../infrastructure/ai/providers/gemini/gemini.provider.js';
import { PROMPTS } from '../../../infrastructure/ai/providers/gemini/prompts.js';
import { ThreadType } from '../../../infrastructure/messaging/zalo/zalo.service.js';
import {
  getHistory,
  saveResponseToHistory,
  saveToHistory,
  saveToolResultToHistory,
} from '../../../shared/utils/history/history.js';
import { setThreadType } from '../../../shared/utils/message/messageSender.js';
import { markPendingToolExecution } from '../../../shared/utils/taskManager.js';
// Import t·ª´ classifier
import {
  type ClassifiedMessage,
  classifyMessages,
  countMessageTypes,
  isBotMentioned,
  type MessageType,
} from '../classifier.js';
import { checkRateLimit, markApiCall } from '../guards/rate-limit.guard.js';
import { createStreamCallbacks, sendResponse } from '../handlers/response.handler.js';
import { handleToolCalls, isToolOnlyResponse } from '../handlers/tool.handler.js';
import { startTypingWithRefresh } from '../services/message.buffer.js';
import { buildPrompt, extractTextFromMessages, processPrefix } from '../services/prompt.builder.js';
import { extractQuoteInfo } from '../services/quote.parser.js';
import { addQuoteMedia, prepareMediaParts } from './media.processor.js';

/**
 * Handler CH√çNH - x·ª≠ l√Ω T·∫§T C·∫¢ lo·∫°i tin nh·∫Øn trong 1 flow duy nh·∫•t
 */
export async function handleMixedContent(
  api: any,
  messages: any[],
  threadId: string,
  signal?: AbortSignal,
) {
  // 1. Ph√¢n lo·∫°i t·∫•t c·∫£ tin nh·∫Øn
  const classified = classifyMessages(messages);
  const counts = countMessageTypes(classified);

  console.log(
    `[Bot] üì¶ X·ª≠ l√Ω ${messages.length} tin nh·∫Øn: ` +
      Object.entries(counts)
        .filter(([_, v]) => v > 0)
        .map(([k, v]) => `${v} ${k}`)
        .join(', '),
  );
  logStep('handleMixedContent', { threadId, counts, total: messages.length });

  try {
    // 2. L∆∞u v√†o history (lu√¥n l∆∞u ƒë·ªÉ Bot nh·ªõ m·ªçi th·ª© k·ªÉ c·∫£ khi im l·∫∑ng)
    for (const msg of messages) {
      await saveToHistory(threadId, msg);
    }

    // 3. X√°c ƒë·ªãnh lo·∫°i Thread (User hay Group)
    const lastMsg = messages[messages.length - 1];
    const isGroup = lastMsg.type === ThreadType.Group;

    // 4. Logic ch·∫∑n tr·∫£ l·ªùi trong nh√≥m n·∫øu kh√¥ng ƒë∆∞·ª£c mention
    if (isGroup) {
      const botId = api.getContext().uid;
      const botName = CONFIG.name || 'Zia';

      // Ki·ªÉm tra xem c√≥ tin nh·∫Øn n√†o trong batch nh·∫Øc t·ªõi Bot kh√¥ng
      const mentioned = messages.some((msg) => isBotMentioned(msg, botId, botName));

      if (!mentioned) {
        debugLog('GATEWAY', `Group message saved to history but ignored (no mention): ${threadId}`);
        return; // D·ª´ng x·ª≠ l√Ω - kh√¥ng typing, kh√¥ng g·ªçi AI
      }

      console.log(`[Bot] üîî ƒê∆∞·ª£c tag trong nh√≥m ${threadId}, ƒëang tr·∫£ l·ªùi...`);
    }

    if (signal?.aborted) return debugLog('MIXED', 'Aborted before processing');

    // G·ª≠i typing event v·ªõi ƒë√∫ng ThreadType (c√≥ auto-refresh)
    const threadType = isGroup ? ThreadType.Group : ThreadType.User;
    // L∆∞u ThreadType ƒë·ªÉ c√°c h√†m response s·ª≠ d·ª•ng
    setThreadType(threadId, threadType);
    startTypingWithRefresh(api, threadId);

    // 5. L·∫•y history v√† context
    const history = getHistory(threadId);

    // 4. Parse quote
    const { quoteContent, quoteMedia } = extractQuoteInfo(lastMsg);

    // 5. L·∫•y text t·ª´ t·∫•t c·∫£ tin nh·∫Øn
    const combinedText = extractTextFromMessages(classified);

    // 6. Check prefix
    const { shouldContinue, userText } = processPrefix(
      combinedText,
      CONFIG.requirePrefix,
      CONFIG.prefix,
    );

    if (!shouldContinue) {
      await api.sendMessage(PROMPTS.prefixHint(CONFIG.prefix), threadId, threadType);
      return;
    }

    // 7. Chu·∫©n b·ªã media parts
    const { media, notes } = await prepareMediaParts(api, classified);
    if (signal?.aborted) return;

    // 8. Th√™m media t·ª´ quote n·∫øu c√≥ (truy·ªÅn history ƒë·ªÉ check media ƒë√£ c√≥ ch∆∞a)
    await addQuoteMedia(api, quoteMedia, media, notes, history);

    // 9. Check YouTube
    const youtubeUrls = extractYouTubeUrls(combinedText);
    if (youtubeUrls.length > 0) {
      console.log(`[Bot] üé¨ Ph√°t hi·ªán ${youtubeUrls.length} YouTube video`);
      youtubeUrls.forEach((url) => media.push({ type: 'youtube', url }));
    }

    // 10. Build prompt
    const quoteHasMedia = quoteMedia.type !== 'none';
    const quoteMediaType = quoteHasMedia ? quoteMedia.type : undefined;
    const prompt = buildPrompt(
      classified,
      userText,
      quoteContent,
      quoteHasMedia,
      quoteMediaType,
      youtubeUrls,
      notes,
    );
    debugLog('MIXED', `Prompt: ${prompt.substring(0, 200)}...`);
    debugLog('MIXED', `Media parts: ${media.length}`);

    // 11. Check rate limit
    const waitTime = checkRateLimit(threadId);
    if (waitTime > 0) {
      const waitSec = Math.ceil(waitTime / 1000);
      console.log(`[Bot] ‚è≥ Rate limit: ch·ªù ${waitSec}s`);
      await api.sendMessage(PROMPTS.rateLimit(waitSec), threadId, threadType);
      await new Promise((r) => setTimeout(r, waitTime));
      if (signal?.aborted) return;
    }
    markApiCall(threadId);

    // 12. G·ªçi Gemini v√† x·ª≠ l√Ω response
    const mediaToSend = media.length > 0 ? media : undefined;
    const senderId = lastMsg.data?.uidFrom || threadId;
    const senderName = lastMsg.data?.dName;

    await processAIResponse(
      api,
      threadId,
      lastMsg,
      messages,
      prompt,
      mediaToSend,
      history,
      senderId,
      senderName,
      signal,
      0,
    );
  } catch (e: any) {
    if (e.message === 'Aborted' || signal?.aborted) {
      return debugLog('MIXED', 'Aborted during processing');
    }
    logError('handleMixedContent', e);
    console.error('[Bot] L·ªói x·ª≠ l√Ω:', e);
  }
}

/**
 * X·ª≠ l√Ω AI response v·ªõi tool support (recursive)
 */
async function processAIResponse(
  api: any,
  threadId: string,
  lastMsg: any,
  messages: any[],
  currentPrompt: string,
  currentMedia: MediaPart[] | undefined,
  currentHistory: any[],
  senderId: string,
  senderName: string | undefined,
  signal: AbortSignal | undefined,
  depth: number,
): Promise<void> {
  const MAX_TOOL_DEPTH = CONFIG.maxToolDepth || 10;
  if (depth >= MAX_TOOL_DEPTH) {
    console.log(`[Bot] ‚ö†Ô∏è ƒê·∫°t gi·ªõi h·∫°n tool depth (${MAX_TOOL_DEPTH})`);
    return;
  }

  if (CONFIG.useStreaming) {
    await processStreamingResponse(
      api,
      threadId,
      lastMsg,
      messages,
      currentPrompt,
      currentMedia,
      currentHistory,
      senderId,
      senderName,
      signal,
      depth,
    );
  } else {
    await processNonStreamingResponse(
      api,
      threadId,
      lastMsg,
      messages,
      currentPrompt,
      currentMedia,
      currentHistory,
      senderId,
      senderName,
      signal,
      depth,
    );
  }
}

/**
 * X·ª≠ l√Ω streaming response
 */
async function processStreamingResponse(
  api: any,
  threadId: string,
  lastMsg: any,
  messages: any[],
  currentPrompt: string,
  currentMedia: MediaPart[] | undefined,
  currentHistory: any[],
  senderId: string,
  senderName: string | undefined,
  signal: AbortSignal | undefined,
  depth: number,
): Promise<void> {
  const callbacks = createStreamCallbacks(api, threadId, lastMsg, messages, true);
  callbacks.signal = signal;

  const result = await generateContentStream(
    currentPrompt,
    callbacks,
    currentMedia,
    threadId,
    currentHistory,
  );

  if (signal?.aborted) {
    debugLog('MIXED', `Aborted with ${result ? 'partial' : 'no'} response`);
    if (result) {
      await saveResponseToHistory(threadId, result);

      // N·∫øu c√≥ tool call trong response, v·∫´n execute tool tr∆∞·ªõc khi return
      // ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o tool nh∆∞ freepikImage v·∫´n g·ª≠i ·∫£nh d√π b·ªã abort
      const toolResult = await handleToolCalls(result, api, threadId, senderId, senderName);
      if (toolResult.hasTools) {
        debugLog('MIXED', `Executing ${toolResult.toolCalls.length} tool(s) despite abort`);
        // L∆∞u tool result v√†o history ƒë·ªÉ AI bi·∫øt tool ƒë√£ ch·∫°y
        await saveToolResultToHistory(threadId, toolResult.promptForAI);
        // ƒê√°nh d·∫•u ƒë·ªÉ buffer bi·∫øt kh√¥ng c·∫ßn merge messages
        markPendingToolExecution(threadId);
      }
    }
    return;
  }

  if (!result) return;

  // Check for tool calls
  const toolResult = await handleToolCalls(result, api, threadId, senderId, senderName);

  if (toolResult.hasTools) {
    debugLog('MIXED', `Tool detected: ${toolResult.toolCalls.map((t) => t.toolName).join(', ')}`);

    await saveResponseToHistory(threadId, result);
    await saveToolResultToHistory(threadId, toolResult.promptForAI);

    const updatedHistory = getHistory(threadId);
    await processAIResponse(
      api,
      threadId,
      lastMsg,
      messages,
      toolResult.promptForAI,
      undefined,
      updatedHistory,
      senderId,
      senderName,
      signal,
      depth + 1,
    );
  } else {
    await saveResponseToHistory(threadId, result);
    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi (streaming)!`);
  }
}

/**
 * X·ª≠ l√Ω non-streaming response
 */
async function processNonStreamingResponse(
  api: any,
  threadId: string,
  lastMsg: any,
  messages: any[],
  currentPrompt: string,
  currentMedia: MediaPart[] | undefined,
  currentHistory: any[],
  senderId: string,
  senderName: string | undefined,
  signal: AbortSignal | undefined,
  depth: number,
): Promise<void> {
  const aiReply = await generateContent(currentPrompt, currentMedia, threadId, currentHistory);

  const responseText = aiReply.messages
    .map((m) => m.text)
    .filter(Boolean)
    .join(' ');

  // N·∫øu b·ªã abort, v·∫´n execute tool tr∆∞·ªõc khi return (gi·ªëng streaming)
  if (signal?.aborted) {
    debugLog('MIXED', `Aborted (non-streaming) with response`);
    if (responseText) {
      await saveResponseToHistory(threadId, responseText);

      // N·∫øu c√≥ tool call trong response, v·∫´n execute tool tr∆∞·ªõc khi return
      const toolResult = await handleToolCalls(responseText, api, threadId, senderId, senderName);
      if (toolResult.hasTools) {
        debugLog(
          'MIXED',
          `Executing ${toolResult.toolCalls.length} tool(s) despite abort (non-streaming)`,
        );
        await saveToolResultToHistory(threadId, toolResult.promptForAI);
        markPendingToolExecution(threadId);
      }
    }
    return;
  }

  const toolResult = await handleToolCalls(responseText, api, threadId, senderId, senderName);

  if (toolResult.hasTools) {
    if (!isToolOnlyResponse(responseText)) {
      await sendResponse(
        api,
        {
          ...aiReply,
          messages: aiReply.messages.map((m) => ({
            ...m,
            text: m.text ? toolResult.cleanedResponse : m.text,
          })),
        },
        threadId,
        lastMsg,
        messages,
      );
    }

    await saveResponseToHistory(threadId, responseText);
    await saveToolResultToHistory(threadId, toolResult.promptForAI);

    const updatedHistory = getHistory(threadId);
    await processAIResponse(
      api,
      threadId,
      lastMsg,
      messages,
      toolResult.promptForAI,
      undefined,
      updatedHistory,
      senderId,
      senderName,
      signal,
      depth + 1,
    );
  } else {
    await sendResponse(api, aiReply, threadId, lastMsg, messages);
    await saveResponseToHistory(threadId, responseText);
    console.log(`[Bot] ‚úÖ ƒê√£ tr·∫£ l·ªùi!`);
  }
}
