/**
 * Gemini Service - Re-export t·ª´ c√°c sub-modules
 *
 * C·∫•u tr√∫c:
 * - geminiConfig.ts: C·∫•u h√¨nh v√† kh·ªüi t·∫°o
 * - geminiChat.ts: Qu·∫£n l√Ω chat sessions
 * - geminiStream.ts: X·ª≠ l√Ω streaming
 */
import type { Content } from '@google/genai';
import { CONFIG } from '../../../../core/config/config.js';
import {
  debugLog,
  logAIHistory,
  logAIResponse,
  logError,
  logStep,
} from '../../../../core/logger/logger.js';
import {
  type AIResponse,
  DEFAULT_RESPONSE,
  parseAIResponse,
} from '../../../../shared/types/config.schema.js';
import { checkInputTokens } from '../../../../shared/utils/tokenCounter.js';
import {
  buildMessageParts,
  deleteChatSession,
  getChatSession,
  isRetryableError,
  sleep,
} from './geminiChat.js';
import { keyManager, type MediaPart } from './geminiConfig.js';
import { isRateLimitError } from './keyManager.js';

export { parseAIResponse } from '../../../../shared/types/config.schema.js';
export { deleteChatSession, getChatSession } from './geminiChat.js';
export type { MediaPart, MediaType } from './geminiConfig.js';
// Re-exports
export {
  extractYouTubeUrls,
  GEMINI_CONFIG,
  getAI,
  getGeminiModel,
  keyManager,
} from './geminiConfig.js';
export type { StreamCallbacks } from './geminiStream.js';
export { generateContentStream } from './geminiStream.js';
export { isRateLimitError } from './keyManager.js';

/**
 * Generate content s·ª≠ d·ª•ng Chat session (non-streaming)
 */
export async function generateContent(
  prompt: string,
  media?: MediaPart[],
  threadId?: string,
  history?: Content[],
): Promise<AIResponse> {
  const mediaTypes = media?.map((m) => m.type) || [];
  logStep('generateContent', {
    type: media?.length ? 'with-media' : 'text-only',
    mediaCount: media?.length || 0,
    mediaTypes,
    promptLength: prompt.length,
    hasThread: !!threadId,
  });

  // Build parts tr∆∞·ªõc ƒë·ªÉ ƒë·∫øm token ch√≠nh x√°c (bao g·ªìm c·∫£ media)
  const parts = await buildMessageParts(prompt, media);

  // Ki·ªÉm tra token ƒë·∫ßu v√†o (prompt + media) tr∆∞·ªõc khi g·ªçi AI
  const inputContent: Content = { role: 'user', parts };
  const tokenCheck = await checkInputTokens([inputContent], CONFIG.maxInputTokens);

  if (!tokenCheck.allowed) {
    console.log(
      `[Gemini] ‚ö†Ô∏è Token limit exceeded: ${tokenCheck.totalTokens}/${tokenCheck.maxTokens}`,
    );
    debugLog('GEMINI', `Token limit exceeded: ${tokenCheck.totalTokens}/${tokenCheck.maxTokens}`);

    // Tr·∫£ v·ªÅ response v·ªõi th√¥ng b√°o l·ªói
    return {
      reactions: [],
      messages: [
        {
          text: tokenCheck.message || 'Token limit exceeded',
          sticker: '',
          quoteIndex: -1,
        },
      ],
      undoIndexes: [],
    };
  }

  const sessionId = threadId || `temp_${Date.now()}`;

  if (media?.length) {
    console.log(
      `[Gemini] üì¶ X·ª≠ l√Ω: ${media.length} media (${[...new Set(mediaTypes)].join(', ')})`,
    );
  }

  let lastError: any = null;
  let skipDelay = false; // Skip delay khi v·ª´a ƒë·ªïi key (rate limit)

  // Retry loop
  for (let attempt = 0; attempt <= CONFIG.retry.maxRetries; attempt++) {
    if (attempt > 0 && !skipDelay) {
      const delayMs = CONFIG.retry.baseDelayMs * 2 ** (attempt - 1);
      console.log(`[Gemini] üîÑ Retry ${attempt}/${CONFIG.retry.maxRetries} sau ${delayMs}ms...`);
      debugLog('GEMINI', `Retry attempt ${attempt}, delay=${delayMs}ms`);
      await sleep(delayMs);
    }
    skipDelay = false; // Reset flag

    if (attempt > 0) {
      deleteChatSession(sessionId);
    }

    try {
      const chat = getChatSession(sessionId, history);
      debugLog('GEMINI', `Using chat session: ${sessionId}, history=${history?.length || 0}`);

      if (history && history.length > 0) {
        logAIHistory(sessionId, history);
      }

      const response = await chat.sendMessage({ message: parts });
      const rawText = response.text || '{}';

      if (attempt > 0) {
        console.log(`[Gemini] ‚úÖ Retry th√†nh c√¥ng sau ${attempt} l·∫ßn th·ª≠`);
      }

      if (!threadId) deleteChatSession(sessionId);

      logAIResponse(prompt.substring(0, 100), rawText);
      return parseAIResponse(rawText);
    } catch (error: any) {
      lastError = error;

      // X·ª≠ l√Ω l·ªói 429 (rate limit) - chuy·ªÉn key/model v√† g·ªçi NGAY
      if (isRateLimitError(error)) {
        const rotated = keyManager.handleRateLimitError();
        if (rotated && attempt < CONFIG.retry.maxRetries) {
          console.log(
            `[Gemini] ‚ö†Ô∏è L·ªói 429: Rate limit, chuy·ªÉn sang key #${keyManager.getCurrentKeyIndex()}/${keyManager.getTotalKeys()} (${keyManager.getCurrentModelName()}) - g·ªçi ngay`,
          );
          debugLog(
            'GEMINI',
            `Rate limit, rotated to key #${keyManager.getCurrentKeyIndex()}, model=${keyManager.getCurrentModelName()}, calling immediately`,
          );
          skipDelay = true; // ƒê·ªïi key r·ªìi, g·ªçi ngay kh√¥ng c·∫ßn delay
          continue;
        }
      }

      // X·ª≠ l√Ω c√°c l·ªói retryable kh√°c (503, etc.) - C·∫¶N delay
      if (isRetryableError(error) && attempt < CONFIG.retry.maxRetries) {
        console.log(`[Gemini] ‚ö†Ô∏è L·ªói ${error.status || error.code}: Model overloaded, s·∫Ω retry...`);
        debugLog('GEMINI', `Retryable error: ${error.status || error.code}`);
        continue;
      }

      break;
    }
  }

  logError('generateContent', lastError);
  console.error('Gemini Error:', lastError);

  if (threadId) {
    debugLog('GEMINI', `Error with chat session, resetting thread ${threadId}`);
    deleteChatSession(threadId);
  }

  return DEFAULT_RESPONSE;
}
